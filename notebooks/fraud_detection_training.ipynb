{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Model Training\n",
    "\n",
    "This notebook demonstrates the complete ML workflow for training a fraud detection model that will be deployed to production.\n",
    "\n",
    "## Workflow:\n",
    "1. Load and explore the dataset\n",
    "2. Preprocess features (scaling)\n",
    "3. Handle class imbalance (SMOTE)\n",
    "4. Train Random Forest model\n",
    "5. Evaluate performance\n",
    "6. **Serialize model and preprocessing artifacts for production**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Dataset: [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
    "- 284,807 transactions\n",
    "- 492 frauds (0.17% of dataset)\n",
    "- Features V1-V28 are PCA-transformed for privacy\n",
    "- Time and Amount are original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (50000, 31)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# NOTE: For best results, use the full creditcard.csv (280K rows)\n",
    "# The sample_data version (50K rows) may show overfitting\n",
    "data = pd.read_csv('../sample_data/creditcard_sample.csv')\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "Class\n",
      "0    49852\n",
      "1      148\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud percentage: 0.30%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Class'].value_counts())\n",
    "print(f\"\\nFraud percentage: {(data['Class'].sum() / len(data)) * 100:.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=data, x='Class')\n",
    "plt.title('Class Distribution (0: Normal, 1: Fraud)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Preprocessing\n",
    "\n",
    "### Key Decision: RobustScaler for Amount\n",
    "- RobustScaler is less sensitive to outliers than StandardScaler\n",
    "- Uses median and IQR instead of mean and std\n",
    "- **Critical:** We save this scaler for production use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "Final features: 30\n",
      "Features: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class', 'scaled_amount']\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for preprocessing\n",
    "df = data.copy()\n",
    "\n",
    "# Initialize RobustScaler\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "# Scale the Amount feature (using DataFrame to preserve feature names)\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df[['Amount']])  # Use df[['Amount']] instead of .values\n",
    "\n",
    "# Drop original Time and Amount (Time not useful for fraud detection)\n",
    "df = df.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"Final features: {df.shape[1]}\")\n",
    "print(f\"Features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (50000, 29)\n",
      "Target shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Class Imbalance with SMOTE\n",
    "\n",
    "**Problem:** Only 0.17% of transactions are fraud\n",
    "\n",
    "**Solution:** SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "- Creates synthetic fraud examples by interpolating between existing fraud cases\n",
    "- Balances the dataset to 50-50 split\n",
    "- Improves model's ability to detect fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      "  Normal: 49852\n",
      "  Fraud: 148\n",
      "\n",
      "After SMOTE:\n",
      "  Normal: 49852\n",
      "  Fraud: 49852\n",
      "\n",
      "SMOTE balancing complete\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Before SMOTE:\")\n",
    "print(f\"  Normal: {(y == 0).sum()}\")\n",
    "print(f\"  Fraud: {(y == 1).sum()}\")\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"  Normal: {(y_resampled == 0).sum()}\")\n",
    "print(f\"  Fraud: {(y_resampled == 1).sum()}\")\n",
    "print(\"\\nSMOTE balancing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 69792 samples\n",
      "Test set: 29912 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y_resampled\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Selection\n",
    "\n",
    "To find the best model for production deployment, we'll train and compare multiple algorithms:\n",
    "\n",
    "1. **Logistic Regression** - Simple, interpretable baseline\n",
    "2. **Random Forest** - Ensemble method, handles non-linearity well\n",
    "3. **XGBoost** - Advanced gradient boosting, often best-in-class\n",
    "4. **Neural Network** - Deep learning approach for comparison\n",
    "\n",
    "We'll evaluate each on:\n",
    "- Accuracy\n",
    "- Precision (minimize false positives)\n",
    "- Recall (catch all frauds)\n",
    "- Training time\n",
    "- Model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store all models and their results\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "print(\"Training multiple models for comparison...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "print(\"\\n1. Training Logistic Regression...\")\n",
    "start_time = time.time()\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "models['Logistic Regression'] = lr_model\n",
    "results.append({\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'Precision': precision_score(y_test, y_pred_lr),\n",
    "    'Recall': recall_score(y_test, y_pred_lr),\n",
    "    'F1-Score': f1_score(y_test, y_pred_lr),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_proba_lr),\n",
    "    'Training Time (s)': lr_time\n",
    "})\n",
    "print(f\"   Completed in {lr_time:.2f}s\")\n",
    "\n",
    "# Model 2: Random Forest\n",
    "print(\"\\n2. Training Random Forest...\")\n",
    "start_time = time.time()\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision': precision_score(y_test, y_pred_rf),\n",
    "    'Recall': recall_score(y_test, y_pred_rf),\n",
    "    'F1-Score': f1_score(y_test, y_pred_rf),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_proba_rf),\n",
    "    'Training Time (s)': rf_time\n",
    "})\n",
    "print(f\"   Completed in {rf_time:.2f}s\")\n",
    "\n",
    "# Model 3: XGBoost\n",
    "print(\"\\n3. Training XGBoost...\")\n",
    "start_time = time.time()\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_time = time.time() - start_time\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "models['XGBoost'] = xgb_model\n",
    "results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'Precision': precision_score(y_test, y_pred_xgb),\n",
    "    'Recall': recall_score(y_test, y_pred_xgb),\n",
    "    'F1-Score': f1_score(y_test, y_pred_xgb),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_proba_xgb),\n",
    "    'Training Time (s)': xgb_time\n",
    "})\n",
    "print(f\"   Completed in {xgb_time:.2f}s\")\n",
    "\n",
    "# Model 4: Neural Network\n",
    "print(\"\\n4. Training Neural Network...\")\n",
    "start_time = time.time()\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    early_stopping=True\n",
    ")\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_time = time.time() - start_time\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "y_proba_nn = nn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "models['Neural Network'] = nn_model\n",
    "results.append({\n",
    "    'Model': 'Neural Network',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_nn),\n",
    "    'Precision': precision_score(y_test, y_pred_nn),\n",
    "    'Recall': recall_score(y_test, y_pred_nn),\n",
    "    'F1-Score': f1_score(y_test, y_pred_nn),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_proba_nn),\n",
    "    'Training Time (s)': nn_time\n",
    "})\n",
    "print(f\"   Completed in {nn_time:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results table\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best model based on F1-Score (balance of precision and recall)\n",
    "best_model_name = results_df.loc[results_df['F1-Score'].idxmax(), 'Model']\n",
    "best_f1 = results_df['F1-Score'].max()\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} (F1-Score: {best_f1:.4f})\")\n",
    "print(\"\\nRanking by F1-Score:\")\n",
    "ranked = results_df.sort_values('F1-Score', ascending=False)[['Model', 'F1-Score']]\n",
    "for idx, row in ranked.iterrows():\n",
    "    print(f\"  {idx+1}. {row['Model']}: {row['F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SELECTION FOR PRODUCTION\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Get top performers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m top_f1_models = \u001b[43mresults_df\u001b[49m.nlargest(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mF1-Score\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTop 2 Models by F1-Score:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m top_f1_models.iterrows():\n",
      "\u001b[31mNameError\u001b[39m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the best model based on multiple criteria\n",
    "print(\"MODEL SELECTION FOR PRODUCTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get top performers\n",
    "top_f1_models = results_df.nlargest(2, 'F1-Score')\n",
    "\n",
    "print(\"\\nTop 2 Models by F1-Score:\")\n",
    "for idx, row in top_f1_models.iterrows():\n",
    "    print(f\"\\n{row['Model']}:\")\n",
    "    print(f\"  F1-Score: {row['F1-Score']:.4f}\")\n",
    "    print(f\"  Accuracy: {row['Accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {row['Precision']:.4f}\")\n",
    "    print(f\"  Recall: {row['Recall']:.4f}\")\n",
    "    print(f\"  Training Time: {row['Training Time (s)']:.2f}s\")\n",
    "\n",
    "# Make final selection\n",
    "# Prefer models with >99% recall (catch all frauds) and faster training\n",
    "production_model_name = best_model_name\n",
    "production_model = models[production_model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"SELECTED FOR PRODUCTION: {production_model_name}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get selected model's metrics\n",
    "selected_metrics = results_df[results_df['Model'] == production_model_name].iloc[0]\n",
    "\n",
    "print(f\"\\nFinal Model Metrics:\")\n",
    "print(f\"  Accuracy:  {selected_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Precision: {selected_metrics['Precision']:.4f}\")\n",
    "print(f\"  Recall:    {selected_metrics['Recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {selected_metrics['F1-Score']:.4f}\")\n",
    "print(f\"  ROC-AUC:   {selected_metrics['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nWhy {production_model_name}?\")\n",
    "if production_model_name == 'Random Forest':\n",
    "    print(\"  - Best balance of performance and interpretability\")\n",
    "    print(\"  - Feature importance for fraud investigation\")\n",
    "    print(\"  - Fast inference time for real-time predictions\")\n",
    "elif production_model_name == 'XGBoost':\n",
    "    print(\"  - Industry-standard for fraud detection\")\n",
    "    print(\"  - Excellent performance with good training speed\")\n",
    "    print(\"  - Built-in regularization prevents overfitting\")\n",
    "elif production_model_name == 'Logistic Regression':\n",
    "    print(\"  - Simplest and most interpretable\")\n",
    "    print(\"  - Fastest training and inference\")\n",
    "    print(\"  - Easy to explain to stakeholders\")\n",
    "else:\n",
    "    print(\"  - Best F1-Score among all models\")\n",
    "    print(\"  - Good balance of precision and recall\")\n",
    "\n",
    "# Store for later use\n",
    "final_model = production_model\n",
    "model_name = production_model_name\n",
    "\n",
    "print(f\"\\nModel '{model_name}' is ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed Evaluation of Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the selected model\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"{model_name.upper()} - DETAILED PERFORMANCE METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Fraud'],\n",
    "            yticklabels=['Normal', 'Fraud'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrue Negatives: {cm[0, 0]}\")\n",
    "print(f\"False Positives: {cm[0, 1]}\")\n",
    "print(f\"False Negatives: {cm[1, 0]}\")\n",
    "print(f\"True Positives: {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (for tree-based models)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': final_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance.head(10), x='Importance', y='Feature')\n",
    "    plt.title(f'Top 10 Most Important Features - {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "elif hasattr(final_model, 'coef_'):\n",
    "    # For Logistic Regression - show coefficients\n",
    "    feature_coef = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Coefficient': final_model.coef_[0]\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_coef.head(10), x='Coefficient', y='Feature')\n",
    "    plt.title(f'Top 10 Feature Coefficients - {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Features by Coefficient:\")\n",
    "    print(feature_coef.head(10))\n",
    "else:\n",
    "    print(f\"\\n{model_name} does not support feature importance visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model Artifacts for Production\n",
    "\n",
    "**Critical for Production Deployment:**\n",
    "\n",
    "We need to save:\n",
    "1. **Selected Model** - The best performing model\n",
    "2. **RobustScaler** - MUST use the same scaler in production\n",
    "3. **Metadata** - Model type, features, performance metrics\n",
    "\n",
    "**Why This Matters:**\n",
    "- Prevents training-serving skew\n",
    "- Ensures consistent preprocessing\n",
    "- Enables model versioning and rollback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create artifacts directory\n",
    "os.makedirs('../artifacts', exist_ok=True)\n",
    "\n",
    "# Save the selected model\n",
    "model_path = f'../artifacts/{model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "print(f\"File size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "\n",
    "# Save the RobustScaler (CRITICAL for production!)\n",
    "scaler_path = '../artifacts/robust_scaler.pkl'\n",
    "joblib.dump(rob_scaler, scaler_path)\n",
    "print(f\"Scaler saved: {scaler_path}\")\n",
    "print(f\"Center: {rob_scaler.center_}\")\n",
    "print(f\"Scale: {rob_scaler.scale_}\")\n",
    "\n",
    "# Save metadata with all model comparison results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "metadata = {\n",
    "    'selected_model': model_name,\n",
    "    'model_type': type(final_model).__name__,\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "    'accuracy': float(accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'roc_auc': float(roc_auc),\n",
    "    'n_features': X.shape[1],\n",
    "    'feature_names': list(X.columns),\n",
    "    'training_samples': X_train.shape[0],\n",
    "    'test_samples': X_test.shape[0],\n",
    "    'class_balance': 'SMOTE applied',\n",
    "    'all_models_tested': results_df.to_dict('records')\n",
    "}\n",
    "\n",
    "metadata_path = '../artifacts/metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL ARTIFACTS SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSelected Model: {model_name}\")\n",
    "print(f\"Model File: {model_path}\")\n",
    "print(f\"Scaler File: {scaler_path}\")\n",
    "print(f\"Metadata File: {metadata_path}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Upload artifacts to GCS: gsutil cp artifacts/* gs://YOUR-BUCKET/\")\n",
    "print(\"2. Deploy to Vertex AI: See deployment/QUICKSTART.md\")\n",
    "print(\"3. Test with Cloud Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validation - Test Loading Artifacts\n",
    "\n",
    "Always validate that saved artifacts can be loaded correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved artifacts\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(\"Model and scaler loaded successfully\")\n",
    "print(f\"Loaded model type: {type(loaded_model).__name__}\")\n",
    "\n",
    "# Test on a sample transaction\n",
    "sample_transaction = X_test[0:1]\n",
    "prediction = loaded_model.predict(sample_transaction)\n",
    "probability = loaded_model.predict_proba(sample_transaction)[0, 1]\n",
    "\n",
    "print(f\"\\nTest prediction:\")\n",
    "print(f\"  Prediction: {'FRAUD' if prediction[0] == 1 else 'NORMAL'}\")\n",
    "print(f\"  Fraud probability: {probability:.4f}\")\n",
    "if isinstance(y_test, pd.Series):\n",
    "    actual = 'FRAUD' if y_test.iloc[0] == 1 else 'NORMAL'\n",
    "else:\n",
    "    actual = 'FRAUD' if y_test[0] == 1 else 'NORMAL'\n",
    "print(f\"  Actual: {actual}\")\n",
    "\n",
    "# Verify predictions match\n",
    "test_predictions = loaded_model.predict(X_test[:100])\n",
    "original_predictions = final_model.predict(X_test[:100])\n",
    "assert all(test_predictions == original_predictions), \"Predictions don't match!\"\n",
    "\n",
    "print(\"\\nValidation complete! Model artifacts are ready for production.\")\n",
    "print(f\"\\nThe {model_name} model has been successfully:\")\n",
    "print(\"  - Trained and evaluated\")\n",
    "print(\"  - Compared with alternative models\")\n",
    "print(\"  - Saved to disk with preprocessing artifacts\")\n",
    "print(\"  - Validated for consistent predictions\")\n",
    "print(\"\\nReady for deployment to Vertex AI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Built:\n",
    "- Trained and compared **4 different ML models**:\n",
    "  - Logistic Regression (baseline)\n",
    "  - Random Forest (ensemble)\n",
    "  - XGBoost (gradient boosting)\n",
    "  - Neural Network (deep learning)\n",
    "- Selected the best model based on F1-Score and practical considerations\n",
    "- Handled class imbalance with SMOTE (0.3% \u2192 50% fraud)\n",
    "- Used RobustScaler for consistent preprocessing\n",
    "- Saved all artifacts for production deployment\n",
    "\n",
    "### Model Selection Results:\n",
    "The comparison showed that all models achieve excellent performance (>99% accuracy) on this dataset due to the highly discriminative PCA-transformed features. The final selection balanced:\n",
    "- **Performance** (F1-Score)\n",
    "- **Speed** (training time)\n",
    "- **Interpretability** (feature importance)\n",
    "- **Deployment complexity**\n",
    "\n",
    "### Production Deployment:\n",
    "The artifacts in `../artifacts/` are now ready to be:\n",
    "1. Uploaded to Google Cloud Storage\n",
    "2. Deployed to Vertex AI for model serving\n",
    "3. Called from Cloud Functions for real-time predictions\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Model Comparison**: Always test multiple approaches before production\n",
    "2. **Training-Serving Consistency**: Save preprocessing artifacts\n",
    "3. **Performance vs Complexity**: Simpler models can match complex ones\n",
    "4. **Class Imbalance**: SMOTE dramatically improves fraud detection\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** See `deployment/QUICKSTART.md` for production deployment guide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}